# VLM-architecture

## Vision Language Model í•™ìŠµ í”„ë¡œì íŠ¸

ì´ ì €ì¥ì†ŒëŠ” Vision Language Model(VLM)ì˜ êµ¬ì¡°ì™€ ì‘ë™ ì›ë¦¬ë¥¼ í•™ìŠµí•˜ê¸° ìœ„í•œ ì¢…í•©ì ì¸ í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
VLM-architecture/
â”œâ”€â”€ VLM_Study_Notebook.ipynb    # ë©”ì¸ í•™ìŠµ ë…¸íŠ¸ë¶
â”œâ”€â”€ requirements.txt            # í•„ìš”í•œ íŒ¨í‚¤ì§€ ëª©ë¡
â”œâ”€â”€ README.md                   # í”„ë¡œì íŠ¸ ì„¤ëª…ì„œ
â””â”€â”€ LICENSE                     # ë¼ì´ì„¼ìŠ¤ íŒŒì¼
```

## ğŸš€ ì‹œì‘í•˜ê¸°

### 1. í™˜ê²½ ì„¤ì •

#### Anaconda í™˜ê²½ ìƒì„±
```bash
# ìƒˆë¡œìš´ conda í™˜ê²½ ìƒì„±
conda create -n vlm-study python=3.10 -y

# í™˜ê²½ í™œì„±í™”
conda activate vlm-study

# Jupyter ì„¤ì¹˜
conda install jupyter notebook ipykernel -y
```

#### í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜
```bash
# ê¸°ë³¸ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install torch torchvision transformers datasets pillow requests accelerate

# ë˜ëŠ” requirements.txt ì‚¬ìš©
pip install -r requirements.txt
```

### 2. ë…¸íŠ¸ë¶ ì‹¤í–‰
```bash
jupyter notebook VLM_Study_Notebook.ipynb
```

## ğŸ“š í•™ìŠµ ë‚´ìš©

### ì£¼ìš” í† í”½
1. **VLM ê¸°ë³¸ ê°œë…** - ë©€í‹°ëª¨ë‹¬ AIì˜ ì´í•´
2. **CLIP ëª¨ë¸** - ëŒ€ì¡° í•™ìŠµ ê¸°ë°˜ ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ì´í•´
3. **BLIP ëª¨ë¸** - ì´ë¯¸ì§€ ìº¡ì…”ë‹ ë° VQA
4. **ë©€í‹°ëª¨ë‹¬ ì–´í…ì…˜** - í¬ë¡œìŠ¤ ëª¨ë‹¬ ìƒí˜¸ì‘ìš© ë©”ì»¤ë‹ˆì¦˜
5. **ì‹¤ì œ ì‘ìš© ì‚¬ë¡€** - ì‚°ì—… ì ìš© ì˜ˆì‹œ

### ì‹¤ìŠµ ë‚´ìš©
- âœ… CLIPì„ ì‚¬ìš©í•œ ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê³„ì‚°
- âœ… BLIPìœ¼ë¡œ ìë™ ì´ë¯¸ì§€ ìº¡ì…˜ ìƒì„±
- âœ… ë©€í‹°ëª¨ë‹¬ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ êµ¬í˜„
- âœ… VLM ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ë¶„ì„
- âœ… ì–´í…ì…˜ ê°€ì¤‘ì¹˜ ì‹œê°í™”

## ğŸ¯ í•™ìŠµ ëª©í‘œ

ì´ í”„ë¡œì íŠ¸ë¥¼ í†µí•´ ë‹¤ìŒì„ í•™ìŠµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

- VLMì˜ í•µì‹¬ ì•„í‚¤í…ì²˜ ì´í•´
- ì£¼ìš” VLM ëª¨ë¸ë“¤(CLIP, BLIP, LLaVA)ì˜ íŠ¹ì§• íŒŒì•…
- ë©€í‹°ëª¨ë‹¬ ë°ì´í„° ì²˜ë¦¬ ë°©ë²• ìŠµë“
- ì‹¤ì œ VLM ëª¨ë¸ ì‚¬ìš©ë²• ìµíˆê¸°
- ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì˜ ì‹œê°í™” ë° í•´ì„

## ğŸ”§ ìš”êµ¬ì‚¬í•­

### ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­
- Python 3.8+
- CUDA ì§€ì› GPU (ê¶Œì¥, CPUë¡œë„ ì‹¤í–‰ ê°€ëŠ¥)
- ìµœì†Œ 8GB RAM

### ì†Œí”„íŠ¸ì›¨ì–´ ì˜ì¡´ì„±
- PyTorch 2.0+
- Transformers 4.30+
- Jupyter Notebook
- ê¸°íƒ€ íŒ¨í‚¤ì§€ëŠ” `requirements.txt` ì°¸ì¡°

## ğŸ“– ì¶”ê°€ í•™ìŠµ ìë£Œ

### ë…¼ë¬¸
- [CLIP: Learning Transferable Visual Representations from Natural Language Supervision](https://arxiv.org/abs/2103.00020)
- [BLIP: Bootstrapping Language-Image Pre-training](https://arxiv.org/abs/2201.12086)
- [LLaVA: Large Language and Vision Assistant](https://arxiv.org/abs/2304.08485)

### ìœ ìš©í•œ ë§í¬
- [Hugging Face Transformers](https://huggingface.co/transformers/)
- [OpenAI CLIP](https://github.com/openai/CLIP)
- [BLIP Official Repo](https://github.com/salesforce/BLIP)

## ğŸ¤ ê¸°ì—¬í•˜ê¸°

í”„ë¡œì íŠ¸ ê°œì„ ì„ ìœ„í•œ ê¸°ì—¬ë¥¼ í™˜ì˜í•©ë‹ˆë‹¤!

1. Fork the Project
2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)
3. Commit your Changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the Branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“„ ë¼ì´ì„¼ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„¼ìŠ¤ í•˜ì— ë°°í¬ë©ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ `LICENSE` íŒŒì¼ì„ ì°¸ì¡°í•˜ì„¸ìš”.

## ğŸ“ ë¬¸ì˜

í”„ë¡œì íŠ¸ì— ëŒ€í•œ ì§ˆë¬¸ì´ë‚˜ ì œì•ˆì‚¬í•­ì´ ìˆìœ¼ì‹œë©´ ì´ìŠˆë¥¼ ìƒì„±í•´ ì£¼ì„¸ìš”.

---

**Happy Learning! ğŸ‰**