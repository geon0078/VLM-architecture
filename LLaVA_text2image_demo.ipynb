{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4227bff3",
   "metadata": {},
   "source": [
    "# LLaVA ì´ë¯¸ì§€ ë¶„ì„ ë° ì§ˆë¬¸-ë‹µë³€ ì‹¤ìŠµ (ê³µì‹ ì €ì¥ì†Œ ê¸°ë°˜)\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ [LLaVA ê³µì‹ ì €ì¥ì†Œ](https://github.com/haotian-liu/LLaVA)ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ê³  ì§ˆë¬¸ì— ë‹µí•˜ëŠ” ê³¼ì •ì„ ë‹¨ê³„ë³„ë¡œ ì‹¤ìŠµí•©ë‹ˆë‹¤.\n",
    "\n",
    "**ì¤‘ìš”:** LLaVAëŠ” í…ìŠ¤íŠ¸â†’ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸ì´ ì•„ë‹™ë‹ˆë‹¤. LLaVAëŠ” ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ê³  ì§ˆë¬¸ì— ëŒ€ë‹µí•˜ëŠ” ë¹„ì „-ì–¸ì–´ ëª¨ë¸ì…ë‹ˆë‹¤.\n",
    "\n",
    "## ëª©ì°¨\n",
    "1. LLaVA ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° ì„í¬íŠ¸\n",
    "2. ëª¨ë¸ ë¡œë“œ\n",
    "3. ì´ë¯¸ì§€ì™€ ì§ˆë¬¸ ì¤€ë¹„\n",
    "4. LLaVA ëª¨ë¸ ì‹¤í–‰ (ì´ë¯¸ì§€ ë¶„ì„)\n",
    "5. ê²°ê³¼ ì‹œê°í™”\n",
    "\n",
    "---\n",
    "\n",
    "## 1. í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° ì„í¬íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8870e860",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SAMSUNG\\anaconda3\\envs\\llava\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n"
     ]
    }
   ],
   "source": [
    "# LLaVA ë° ì˜ì¡´ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "import torch\n",
    "from llava.model.builder import load_pretrained_model\n",
    "from llava.mm_utils import get_model_name_from_path\n",
    "from llava.eval.run_llava import eval_model\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a5ac5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required dependencies\n",
    "!pip install protobuf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b733d311",
   "metadata": {},
   "source": [
    "## 2. ëª¨ë¸ ë° í”„ë¡œì„¸ì„œ ë¡œë“œ\n",
    "\n",
    "LLaVA ê³µì‹ APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ì „í•™ìŠµëœ ëª¨ë¸ê³¼ í”„ë¡œì„¸ì„œë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05c0b7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type llava to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.86it/s]\n"
     ]
    }
   ],
   "source": [
    "from llava.model.builder import load_pretrained_model\n",
    "from llava.mm_utils import get_model_name_from_path\n",
    "from llava.eval.run_llava import eval_model\n",
    "import torch\n",
    "\n",
    "model_path = \"liuhaotian/llava-v1.5-7b\"\n",
    "model_name = get_model_name_from_path(model_path)\n",
    "\n",
    "tokenizer, model, image_processor, context_len = load_pretrained_model(\n",
    "    model_path=model_path,\n",
    "    model_base=None,\n",
    "    model_name=model_name,\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    device_map=\"auto\",  # í˜¹ì€ ìˆ˜ë™ ì„¤ì •\n",
    "    offload_folder=\"./offload\"  # ë””ìŠ¤í¬ì— weight ì €ì¥í•  ê²½ë¡œ\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a881e4c7",
   "metadata": {},
   "source": [
    "## 3. ì´ë¯¸ì§€ì™€ ì§ˆë¬¸ ì¤€ë¹„\n",
    "\n",
    "LLaVAì— ì…ë ¥í•  ì´ë¯¸ì§€ì™€ ì§ˆë¬¸ì„ ì¤€ë¹„í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7126289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì¤€ë¹„ëœ ì§ˆë¬¸: ì´ ì´ë¯¸ì§€ì— ìˆëŠ” ë™ë¬¼ì— ëŒ€í•´ ìì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n",
      "ë¶„ì„í•  ì´ë¯¸ì§€: img/cat-1192026_1280.jpg\n"
     ]
    }
   ],
   "source": [
    "# ì´ë¯¸ì§€ì— ëŒ€í•œ ì§ˆë¬¸ ì¤€ë¹„\n",
    "query = \"ì´ ì´ë¯¸ì§€ì— ìˆëŠ” ë™ë¬¼ì— ëŒ€í•´ ìì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.\"\n",
    "print(f\"ì¤€ë¹„ëœ ì§ˆë¬¸: {query}\")\n",
    "\n",
    "# ì‚¬ìš©í•  ì´ë¯¸ì§€ ê²½ë¡œ ì„¤ì •\n",
    "image_path = \"img/cute_kitten.jpg\"  # ì—…ë¡œë“œëœ ê·€ì—¬ìš´ ìƒˆë¼ê³ ì–‘ì´ ì´ë¯¸ì§€\n",
    "print(f\"ë¶„ì„í•  ì´ë¯¸ì§€: {image_path}\")\n",
    "\n",
    "# í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ ì…ë ¥\n",
    "prompt = input(\"cute cat on the beach, sunny day, high quality, 4k resolution, realistic style, vibrant colors, detailed fur, playful expression\")\n",
    "\n",
    "# í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš©í•œ ì „ì²˜ë¦¬\n",
    "tokens = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# ì´ë¯¸ì§€ì— ëŒ€í•œ ë‹¤ì–‘í•œ ì§ˆë¬¸ë“¤ ì¤€ë¹„\n",
    "questions = [\n",
    "    \"ì´ ì´ë¯¸ì§€ì— ìˆëŠ” ë™ë¬¼ì— ëŒ€í•´ ìì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.\",\n",
    "    \"ì´ ê³ ì–‘ì´ì˜ ë‚˜ì´ëŠ” ëŒ€ëµ ëª‡ ì‚´ë¡œ ë³´ì´ë‚˜ìš”?\",\n",
    "    \"ì´ ê³ ì–‘ì´ì˜ í„¸ ìƒ‰ê¹”ê³¼ ë¬´ëŠ¬ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.\",\n",
    "    \"ì´ ê³ ì–‘ì´ì˜ í‘œì •ì´ë‚˜ ê°ì • ìƒíƒœëŠ” ì–´ë– í•œê°€ìš”?\",\n",
    "    \"ì´ ì‚¬ì§„ì€ ì–´ë–¤ í™˜ê²½ì—ì„œ ì´¬ì˜ëœ ê²ƒ ê°™ë‚˜ìš”?\"\n",
    "]\n",
    "\n",
    "# ê¸°ë³¸ ì§ˆë¬¸ ì„ íƒ\n",
    "selected_question = questions[0]\n",
    "print(f\"ì„ íƒëœ ì§ˆë¬¸: {selected_question}\")\n",
    "print(f\"ë¶„ì„í•  ì´ë¯¸ì§€: {image_path}\")\n",
    "\n",
    "# ì´ë¯¸ì§€ íŒŒì¼ ì¡´ì¬ í™•ì¸\n",
    "import os\n",
    "if os.path.exists(image_path):\n",
    "    print(\"âœ“ ì´ë¯¸ì§€ íŒŒì¼ì´ ì¡´ì¬í•©ë‹ˆë‹¤.\")\n",
    "else:\n",
    "    print(\"âœ— ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3fb291",
   "metadata": {},
   "source": [
    "## 4. LLaVA ëª¨ë¸ ì‹¤í–‰ (ì´ë¯¸ì§€ ë¶„ì„)\n",
    "\n",
    "**ì¤‘ìš”:** LLaVAëŠ” í…ìŠ¤íŠ¸â†’ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸ì´ ì•„ë‹™ë‹ˆë‹¤. LLaVAëŠ” ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ê³  ì§ˆë¬¸ì— ëŒ€ë‹µí•˜ëŠ” ë¹„ì „-ì–¸ì–´ ëª¨ë¸ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96141b6d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "eval_model() got an unexpected keyword argument 'model_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mì´ ì´ë¯¸ì§€ì— ìˆëŠ” ë™ë¬¼ì— ëŒ€í•´ ìì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# eval_model í•¨ìˆ˜ ì‚¬ìš© (ì´ë¯¸ì§€ ë¶„ì„ ë° í…ìŠ¤íŠ¸ ìƒì„±)\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43meval_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_base\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_available\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     28\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLLaVA ì‘ë‹µ:\u001b[39m\u001b[38;5;124m\"\u001b[39m, result)\n",
      "\u001b[1;31mTypeError\u001b[0m: eval_model() got an unexpected keyword argument 'model_path'"
     ]
    }
   ],
   "source": [
    "# LLaVA ëª¨ë¸ì„ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ë¶„ì„ ë° ì§ˆë¬¸-ë‹µë³€ (ì˜ˆì‹œ)\n",
    "# LLaVAëŠ” í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ë³€í™˜ ê¸°ëŠ¥ì´ ë‚´ì¥ë˜ì–´ ìˆì§€ ì•Šìœ¼ë©°,\n",
    "# ì£¼ë¡œ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ê³  ì´ì— ëŒ€í•œ ì§ˆë¬¸ì— ë‹µí•˜ëŠ” ë¹„ì „-ì–¸ì–´ ëª¨ë¸ì…ë‹ˆë‹¤.\n",
    "# í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ìƒì„±ì„ ì›í•  ê²½ìš° Stable Diffusion, DALL-E ë“±ì˜ ëª¨ë¸ì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "# ì´ë¯¸ì§€ ë¶„ì„ ë° ì§ˆë¬¸-ë‹µë³€ ì‹¤í–‰\n",
    "# (ê²°ê³¼ëŠ” result ë³€ìˆ˜ì— ì €ì¥ë¨)\n",
    "# ì˜ˆì‹œ: eval_model í•¨ìˆ˜ ì‚¬ìš©\n",
    "# ì°¸ê³ : eval_model í•¨ìˆ˜ì˜ ì¸ìì™€ ë°˜í™˜ê°’ì€ LLaVA ë²„ì „ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "# ì˜ˆì‹œ ì…ë ¥ ì´ë¯¸ì§€\n",
    "image_path = \"img/cat-1192026_1280.jpg\"  # ë¶„ì„í•  ì´ë¯¸ì§€ ê²½ë¡œ\n",
    "\n",
    "# ì´ë¯¸ì§€ì— ëŒ€í•œ ì§ˆë¬¸\n",
    "query = \"ì´ ì´ë¯¸ì§€ì— ìˆëŠ” ë™ë¬¼ì— ëŒ€í•´ ìì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.\"\n",
    "\n",
    "# LLaVA ëª¨ë¸ì„ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ë¶„ì„ ë° ì§ˆë¬¸-ë‹µë³€\n",
    "print(f\"ì´ë¯¸ì§€ ë¶„ì„ ì¤‘: {image_path}\")\n",
    "print(f\"ì§ˆë¬¸: {selected_question}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "try:\n",
    "    # eval_model í•¨ìˆ˜ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ë¶„ì„\n",
    "    result = eval_model(\n",
    "        model_path=model_path,\n",
    "        model_base=None,\n",
    "        model_name=model_name,\n",
    "        query=selected_question,\n",
    "        image_file=image_path,\n",
    "        tokenizer=tokenizer,\n",
    "        model=model,\n",
    "        image_processor=image_processor,\n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    )\n",
    "    \n",
    "    print(\"LLaVA ë¶„ì„ ê²°ê³¼:\")\n",
    "    print(result)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "    print(\"ëª¨ë¸ ë¡œë”©ì´ë‚˜ ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3a370c",
   "metadata": {},
   "source": [
    "## 5. ê²°ê³¼ ì‹œê°í™”\n",
    "\n",
    "ì…ë ¥ ì´ë¯¸ì§€ì™€ LLaVAì˜ í…ìŠ¤íŠ¸ ì‘ë‹µì„ í•¨ê»˜ í‘œì‹œí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35176a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìƒì„± ì´ë¯¸ì§€ ì‹œê°í™” ë° ì €ì¥\n",
    "if generated_image is not None:\n",
    "    if isinstance(generated_image, np.ndarray):\n",
    "        img = Image.fromarray((generated_image * 255).astype(np.uint8))\n",
    "    elif isinstance(generated_image, Image.Image):\n",
    "        img = generated_image\n",
    "    else:\n",
    "        raise ValueError(\"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ íƒ€ì…ì…ë‹ˆë‹¤.\")\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title('LLaVA ìƒì„± ì´ë¯¸ì§€')\n",
    "    plt.show()\n",
    "    img.save('generated_image_llava.png')\n",
    "    print('ì´ë¯¸ì§€ê°€ generated_image_llava.png íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.')\n",
    "else:\n",
    "    print('ìƒì„±ëœ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.')\n",
    "\n",
    "# ì…ë ¥ ì´ë¯¸ì§€ ë° LLaVA ì‘ë‹µ ì‹œê°í™”\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "if os.path.exists(image_path):\n",
    "    # ì…ë ¥ ì´ë¯¸ì§€ í‘œì‹œ\n",
    "    img = Image.open(image_path)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # ì´ë¯¸ì§€ í‘œì‹œ\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title('ë¶„ì„ ëŒ€ìƒ ì´ë¯¸ì§€: ê·€ì—¬ìš´ ìƒˆë¼ê³ ì–‘ì´', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # LLaVA ì‘ë‹µ í‘œì‹œ\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.text(0.05, 0.95, f\"ì§ˆë¬¸: {selected_question}\", \n",
    "             fontsize=12, fontweight='bold', ha='left', va='top', \n",
    "             transform=plt.gca().transAxes, wrap=True)\n",
    "    \n",
    "    plt.text(0.05, 0.8, f\"LLaVA ì‘ë‹µ:\\n{result}\", \n",
    "             fontsize=11, ha='left', va='top', \n",
    "             transform=plt.gca().transAxes, wrap=True)\n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.title('LLaVA ë¶„ì„ ê²°ê³¼', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # ê²°ê³¼ ìš”ì•½ ì¶œë ¥\n",
    "    print(\"=\" * 60)\n",
    "    print(\"ğŸ± LLaVA ì´ë¯¸ì§€ ë¶„ì„ ì™„ë£Œ\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"ğŸ“· ì´ë¯¸ì§€: {image_path}\")\n",
    "    print(f\"â“ ì§ˆë¬¸: {selected_question}\")\n",
    "    print(f\"ğŸ’¬ ì‘ë‹µ: {result}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "else:\n",
    "    print(f\"âŒ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}\")\n",
    "    print(\"ì´ë¯¸ì§€ë¥¼ img/ í´ë”ì— ì €ì¥í–ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9cba4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¶”ê°€ ë¶„ì„: ì—¬ëŸ¬ ì§ˆë¬¸ìœ¼ë¡œ ì´ë¯¸ì§€ ë¶„ì„í•˜ê¸°\n",
    "print(\"ğŸ” ì—¬ëŸ¬ ì§ˆë¬¸ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ ë” ìì„¸íˆ ë¶„ì„í•´ë³´ê² ìŠµë‹ˆë‹¤...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for i, question in enumerate(questions[1:], 1):  # ì²« ë²ˆì§¸ ì§ˆë¬¸ì€ ì´ë¯¸ ë¶„ì„í–ˆìœ¼ë¯€ë¡œ ì œì™¸\n",
    "    print(f\"\\nì§ˆë¬¸ {i+1}: {question}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    try:\n",
    "        result = eval_model(\n",
    "            model_path=model_path,\n",
    "            model_base=None,\n",
    "            model_name=model_name,\n",
    "            query=question,\n",
    "            image_file=image_path,\n",
    "            tokenizer=tokenizer,\n",
    "            model=model,\n",
    "            image_processor=image_processor,\n",
    "            device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        )\n",
    "        \n",
    "        print(f\"ë‹µë³€: {result}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "    \n",
    "    print(\"-\" * 50)\n",
    "\n",
    "print(\"\\nğŸ‰ ëª¨ë“  ì§ˆë¬¸ì— ëŒ€í•œ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llava",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
